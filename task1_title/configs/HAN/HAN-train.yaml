<<<<<<< HEAD:task1_title/configs/HAN/HAN-train.yaml
EXP_NAME: HAN-Part1
=======
EXP_NAME: HAN_w_freeze_w2e-sentence_embedding_contents
>>>>>>> 04b7ae4e9825729d357b7c32fa9c15e7f919f4e9:task1_title/configs/HAN/HAN_w_freeze_w2e-train.yaml
SEED: 223

MODE:
    do_train: True
    do_test: False
    
DATASET:
    name: HAN
<<<<<<< HEAD:task1_title/configs/HAN/HAN-train.yaml
    data_path: ../data/labeled_fake_news/Part1 # news article directory
    saved_data_path: ../data/labeled_fake_news/Part1/HAN_s16_w64
=======
    data_path: ../data/direct_exp/Part1 # news article directory
    data_info_path: ../data/direct_exp/Part1/sentence_embedding_contents # splitted csv file director
    saved_data_path: ../data/direct_exp/Part1/HAN_s16_w64-sentence_embedding_contents
>>>>>>> 04b7ae4e9825729d357b7c32fa9c15e7f919f4e9:task1_title/configs/HAN/HAN_w_freeze_w2e-train.yaml
    PARAMETERS:
        max_sent_len: 16
        max_word_len: 64

TOKENIZER: 
    name: mecab
    vocab_path: ./word-embeddings/glove/glove.txt
    max_vocab_size: 50000  

MODEL:
    modelname: han
    freeze_word_embed: True
    use_pretrained_word_embed: True
    PARAMETERS:
        num_classes: 2
        vocab_len: 50002
        dropout: 0.1
        word_dims: 32
        sent_dims: 64
        embed_dims: 100
    CHECKPOINT:
        pretrained: False
        checkpoint_path: null

TRAIN:
    batch_size: 256
    num_training_steps: 30000
    accumulation_steps: 1
    num_workers: 12
    use_wandb: True

LOG:
    log_interval: 10
    eval_interval: 1000

OPTIMIZER:
    lr: 0.003
    weight_decay: 0.0005

SCHEDULER:
    warmup_ratio: 0.1
    use_scheduler: False

RESULT:
    savedir: './saved_model'
